{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "df1dc0c0",
      "metadata": {
        "id": "df1dc0c0"
      },
      "source": [
        "# Surface Observation Postprocessing with Machine Learning\n",
        "\n",
        "[![](https://img.shields.io/badge/open-colab-yellow)](https://colab.research.google.com/github/ecmwf-projects/mooc-machine-learning-weather-climate/blob/main/tier_2/deep_learning/Surface_Observation_Prediction_in_Tensorflow.ipynb) [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/ecmwf-projects/mooc-machine-learning-weather-climate/blob/main/tier_2/deep_learning/Surface_Observation_Prediction_in_Tensorflow.ipynb) [![Open%20In%20SageMaker%20Studio%20Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/ecmwf-projects/mooc-machine-learning-weather-climate/blob/main/tier_2/deep_learning/Surface_Observation_Prediction_in_Tensorflow.ipynb) [![Launch%20in%20Deepnote](https://deepnote.com/buttons/launch-in-deepnote-small.svg)](https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fecmwf-projects%2Fmooc-machine-learning-weather-climate%2Fblob%2Fmain%2Ftier_2/deep_learning%2FSurface_Observation_Prediction_in_Tensorflow.ipynb)\n",
        "\n",
        "Surface observation processing refers to the process of collecting and analyzing weather observations taken at the Earth's surface by weather stations and other observing platforms. This typically includes measuring temperature, humidity, wind speed and direction, precipitation, and other meteorological variables. The observations are then used to produce weather forecasts and warnings, as well as to analyze and understand weather patterns. The process typically involves quality control checks to ensure the observations are accurate and reliable, as well as the use of automated systems to process and disseminate the observations in near real-time.\n",
        "\n",
        "Surface observation processing is the process of collecting and analyzing weather information taken at ground level by weather stations and other observing platforms. These measurements include temperature, humidity, wind speed and direction, and precipitation. From this information, we can create weather forecasts and warnings and understand weather patterns.\n",
        "\n",
        "Machine learning can be applied in surface observation processing in several ways. One way is to use machine learning algorithms to help improve the accuracy of forecasts by analyzing large amounts of historical weather data. The algorithms can make more accurate predictions about future weather by learning from past weather patterns. Another way machine learning can be applied is in the quality control of the observations. Machine learning models can be trained to identify and flag any observations that may be incorrect or unreliable. This quality control can help ensure that only the most accurate and reliable weather information is used for forecasts and other purposes.\n",
        "\n",
        "In addition, Machine learning can be used to automate the process of surface observation processing, allowing the system to run more efficiently and quickly. This can help produce forecasts and warnings more quickly and with higher accuracy, providing more detailed and accurate information to the public.\n",
        "\n",
        "Overall, the use of Machine learning in surface observation processing can help improve the accuracy and speed of weather forecasting, and provide more detailed and accurate information to the public.\n",
        "\n",
        "In this notebooks, we are experimenting with deep learning techniques to solve a real-world problem that is relatively simple. The goal is to improve the temperature forecast of the ECMWF Integrated Forecast System (IFS) by using a technique called postprocessing.\n",
        "\n",
        "Specifically, we are trying to predict the difference between the temperature observed at a weather station and the temperature forecasted by the IFS at the closest point on the grid to the station. To achieve this, we will look at several different predictors based on physical principles.\n",
        "\n",
        "We will also get to explore several physically motivated predictors.\n",
        "\n",
        "_An example of using machine learning to model weather forecast error based on work of Matthew Chantry and Fenwick Cooper as part of work funded by [IFAB](https://www.ifabfoundation.org/). Modified by Jesper Dramsch for the [MOOC Machine Learning in Weather & Climate](https://ecmwf.int/mlwc-mooc) brough to you by ECMWF in partnership with IFAB._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dbf6081",
      "metadata": {
        "id": "1dbf6081"
      },
      "source": [
        "## Setting up the Notebook\n",
        "\n",
        "First, we need to install the necessary packages using `pip`.\n",
        "\n",
        "We are using Climetlab to load our prepared dataset, which we need to install\n",
        "\n",
        "### Data and Machine Learning Libraries\n",
        "\n",
        "Depending on the compute platform you are using, you may want to install the following packages in addition. These come pre-installed on some online environments like Google Colab, but not on all:\n",
        "\n",
        "- numpy\n",
        "- matplotlib\n",
        "- scikit-learn\n",
        "- tensorflow\n",
        "\n",
        "We added those to the `requirements.txt` for your convenience. If you're trying this exercise locally on Windows, it may be easier installing the libraries with `conda`. Pytorch has a guide to [install locally here](https://pytorch.org/get-started/locally/) and Tensorflow has a guide to [install locally here](https://www.tensorflow.org/install/pip), which may differ from they minimal code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7439fdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7439fdc",
        "outputId": "38909371-2957-4726-ebc8-422c30afde2e"
      },
      "outputs": [],
      "source": [
        "!pip install \"climetlab-mltc-surface-observation-postprocessing>=0.3.0\" --quiet\n",
        "\n",
        "# !pip install numpy matplotlib scikit-learn  --quiet\n",
        "\n",
        "# Tensorflow\n",
        "# !conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0 -yq\n",
        "# !pip install tensorflow  --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0724002c",
      "metadata": {
        "id": "0724002c"
      },
      "source": [
        "We will be using some tools that are commonly used in machine learning. \n",
        "\n",
        "Even though some of the mathematical concepts behind these tools are simple, it's often better to use pre-existing tools that have been tested and refined by others. This will save us time and make our analysis more reliable.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Overview:</b> Numpy is the numerical Python library that is the de facto standard in dealing with scientific data in n-dimensional arrays\n",
        "Matplotlib is a plotting library that can be used to create static, animated, and interactive visualizations of data.\n",
        "Scikit-learn is a machine learning library for Python that provides simple and efficient tools for classic machine learning.\n",
        "Tensorflow is a library for developing and deploying machine learning models, particularly neural networks.\n",
        "Pytorch is a library for developing and deploying machine learning models, particularly deep learning models.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9716a266",
      "metadata": {
        "id": "9716a266"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CliMetLab will be used to manage the data loading.\n",
        "import climetlab as cml\n",
        "\n",
        "# Import a tool for helping make figures\n",
        "from climetlab_mltc_surface_observation_postprocessing.utils import imgBufferFromVectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42b3279",
      "metadata": {
        "id": "c42b3279"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We will be loading a list that contains the errors of temperature forecasts made by the high-resolution forecast system of the European Centre for Medium-Range Weather Forecasts (ECMWF) for a 36-hour period. These forecasts will be compared with temperature measurements taken from about 8000 weather stations located around the world.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\"><strong>Note:</strong> It's important to note that the dataset we're using has already gone through a crucial step of preparation known as data preprocessing. This means that any data that could be considered invalid or unreliable has already been removed. For example, data from weather stations with inconsistent measurement locations, duplicate values, or values that are physically impossible (such as temperatures over 100 degrees Celsius) have been removed. If you're starting a new project, this step of cleaning the data is essential.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d8e4da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "dbd0dc09e89e42df8948ee0d3d830dc0",
            "aec578e613734c778d40ccacbfa46287",
            "1c8d2d0cea59400f8c8235430f801ef3",
            "92a9cc49337c403fb405d8c2e134c3d5",
            "2159bfe5874b4988a12a86a51276f091",
            "99698e34064f41cfa0bc73c46ba3663b",
            "1bb0061217dc4d28ac9841706edc93a7",
            "21dd2a43253842018dd587b905e21ee2",
            "8d0287a5ef9b44d8ac7ca90ef7080cb4",
            "752b9d94e5384d3cb757d45da2b4033d",
            "64b1cb3e8476434b906e317c9328bd2a"
          ]
        },
        "id": "a4d8e4da",
        "outputId": "4fdc816b-3cbd-4872-b848-ef78464d509b"
      },
      "outputs": [],
      "source": [
        "forecast_error = cml.load_dataset(\"mltc-surface-observation-postprocessing\", field=\"forecast_error\").to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28bbad8e",
      "metadata": {
        "id": "28bbad8e"
      },
      "source": [
        "We have a hypothesis that the errors in the forecast can be easily explained by the time of day the measurements were taken. To test this, we will load the local time of day for when the measurements were recorded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b49363",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "64d7eb99a75c46c3a83f820f2d37a20a",
            "1d924eea57bf4996a8daa5f5c3116ffe",
            "d2d85c288705419a94e8f3590951982c",
            "e00c7590687844a6ba18d8be5a79e657",
            "cd6b4f403db84f9db6c913a879a85f31",
            "7420e55e139241bab475af2c1e3a0db4",
            "64882a140c39440e82ab736416ab248e",
            "4e359bb2323148688f83cef9531778fc",
            "4a22dc23cee943e68fead37f9088dcaf",
            "0f4133980c8e4ffdbca2a5f6a64fd93a",
            "436463275b9d41de94b5537597e3f6ea"
          ]
        },
        "id": "d0b49363",
        "outputId": "fadb1a12-9971-4df3-a765-4e4393af6b39"
      },
      "outputs": [],
      "source": [
        "time_of_day = cml.load_dataset(\"mltc-surface-observation-postprocessing\", field=\"time_of_day\").to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ee1569",
      "metadata": {
        "id": "e2ee1569"
      },
      "source": [
        "Later we will add in the soil temperature, so we'll load this here to have the data loading step complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb59e827",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e1437f990544457687ab3749da91fa4a",
            "938dbdbbb5414086a17a4e28b61c9c5b",
            "5d634ff4adca4ac79034ee976fd71d89",
            "0f899f69e52f40039d893cbb47938d37",
            "7b4d084e1fcc4144a1cd651f23c53ee8",
            "5f4309b054b548819d520242304213d4",
            "e2dd4a70b77f493fa8091c60bfebc0c0",
            "1b04146f6af542a28bcb833e8789f131",
            "ef4cf06d35c34b96935c44f6d4cbbe0b",
            "bc45aea02224494e9758bbfa4790fbaa",
            "b26b31016f7e4f49acdc0714e49135d8"
          ]
        },
        "id": "cb59e827",
        "outputId": "3289594d-b239-499e-db15-d34eaf65eb83"
      },
      "outputs": [],
      "source": [
        "soil_temperature = cml.load_dataset(\"mltc-surface-observation-postprocessing\", field=\"soil_temperature\").to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8418195e",
      "metadata": {
        "id": "8418195e"
      },
      "source": [
        "## Data Splitting\n",
        "\n",
        "We will be dividing the data used to make predictions and the data used to predict into two separate groups: training and testing. The training group will consist of 80% of the data and the testing group will consist of 20% of the data. This is done randomly, so that the data in each group is representative of the overall dataset.\n",
        "\n",
        "It's worth noting that the data has already been anonymized, so we can't use information about the weather stations or the time the measurements were taken to make sure that the data subsets are independent. If we had more metadata, we could use the methods we learned earlier to ensure that the data subsets are not dependent on each other.\n",
        "\n",
        "We use the function \"train_test_split\" from the scikit-learn library.\n",
        "\n",
        "The function takes an arbitrary number of inputs to split. Here we provide 3 inputs:\n",
        "\n",
        "- `forecast_error`: it is the data containing errors in forecasted temperatures,\n",
        "- `time_of_day`: it is the data containing the local time of day when the measurements were taken,\n",
        "- `soil_temperature`: it is the data containing the soil temperature at the location where the measurements were taken.\n",
        "\n",
        "The function also takes in two parameters:\n",
        "\n",
        "- `test_size`: it specifies what proportion of the data should be in the testing group. In this case, it is set to 0.2, which means that 20% of the data will be in the testing group and 80% of the data will be in the training group.\n",
        "- `random_state`: it is used for initializing the random number generator and get the same split each time the script is run. Here it is set to `42`, which is an arbitrary number.\n",
        "\n",
        "The function returns 6 outputs:\n",
        "\n",
        "- `forecast_error_train`: it is the data containing errors in forecasted temperatures that will be used for training,\n",
        "- `forecast_error_test`: it is the data containing errors in forecasted temperatures that will be used for testing,\n",
        "- `time_of_day_train`: it is the data containing the local time of day when the measurements were taken that will be used for training,\n",
        "- `time_of_day_test`: it is the data containing the local time of day when the measurements were taken that will be used for testing,\n",
        "- `soil_temperature_train`: it is the data containing the soil temperature at the location where the measurements were taken that will be used for training,\n",
        "- `soil_temperature_test`: it is the data containing the soil temperature at the location where the measurements were taken that will be used for testing.\n",
        "\n",
        "In summary, this code is splitting up the data into training and testing groups, using 80% of the data for training and 20% for testing. And it will be done in a random way and keep the same split each time the script is run by setting random_state to 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df69b984",
      "metadata": {
        "id": "df69b984"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    forecast_error_train,\n",
        "    forecast_error_test,\n",
        "    time_of_day_train,\n",
        "    time_of_day_test,\n",
        "    soil_temperature_train,\n",
        "    soil_temperature_test,\n",
        ") = train_test_split(\n",
        "    forecast_error,\n",
        "    time_of_day,\n",
        "    soil_temperature,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522f791e",
      "metadata": {
        "id": "522f791e"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "The next step is to standardize the data. This is an important step that helps to prepare the data for training a neural network, especially in larger problems. To standardize the data, we will be using a method called `StandardScaler` method from scikit-learn library. This method divides each data point by the mean and standard deviation of the training dataset. By doing this, it ensures that the data has a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "The code creates an instance of the `StandardScaler` class, and assigns it to the variable \"scaler\". Then we use the `fit()` method of this scaler object, which calculates the mean and variance of the `time_of_day_train` data. Note that we fit this object on the training data only, to avoid cheating and accidentally creating a model that seems like it works better than it actually does.\n",
        "\n",
        "We apply the transformation to `time_of_day_train` data and creates a new variable `time_of_day_train_norm` which contains the standardized data.\n",
        "\n",
        "The next line of code applies the same transformation to `time_of_day_test` data and creates a new variable `time_of_day_test_norm` which contains the standardized test data. Note that this only applies the standardization and doesn't learn from the test data, which is valid. This is one of the big benefits of using the `StandardScaler` object.\n",
        "\n",
        "In summary, this code is standardizing the `time_of_day` data by calculating the mean and variance of the training data and then dividing the training and testing data by those values resulting in a new set of data with mean = 0 and variance = 1.\n",
        "\n",
        "It's worth noting that there are other ways to prepare data for a neural network, and sometimes a different approach may be more appropriate. For example, when working with precipitation data, it may be more appropriate to use a log transform instead of standardizing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ffb07a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3ffb07a",
        "outputId": "226d725b-93f4-48a3-e048-b63d8de5a19c"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(time_of_day_train)\n",
        "print(\"Mean:\", scaler.mean_, \", Variance:\", scaler.var_)\n",
        "\n",
        "time_of_day_train_norm = scaler.transform(time_of_day_train)\n",
        "time_of_day_test_norm = scaler.transform(time_of_day_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd5a3ea",
      "metadata": {
        "id": "1cd5a3ea"
      },
      "source": [
        "## Model Building\n",
        "\n",
        "In Tensorflow / Keras we have multiple ways to build a neural network. \n",
        "\n",
        "Two of these approaches will be presented below, namely the sequential and the functional approach.\n",
        "\n",
        "This code defines two functions: \"fullyconnected_sequential\" and \"fullyconnected_functional\". Both functions create a model with a similar structure: it starts with an input layer, followed by several dense layers, and ends with an output layer. \n",
        "\n",
        "But first we import the necessary layers from the tensorflow library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab352f4",
      "metadata": {
        "id": "8ab352f4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c7f4f4",
      "metadata": {
        "id": "a3c7f4f4"
      },
      "source": [
        "### Sequential Model\n",
        "\n",
        "The simplest is the sequential approach here we write a function `fullyconnected_sequential` which is used to build a neural network using the Keras library with a sequential approach. The function takes several parameters:\n",
        "\n",
        "- `input_shape`: an integer representing the number of predictors.\n",
        "- `width`: an integer representing how wide the layers should be.\n",
        "- `depth`: an integer representing how many layers the network should have.\n",
        "- `activation`: a string representing the non-linear activation function to use (e.g. 'relu', 'sigmoid', etc.).\n",
        "- `learning_rate`: a float representing the learning rate of the optimizer (default value is 10^-3).\n",
        "- `final_activation`: a string representing the activation function for the final layer(default value is 'linear').\n",
        "\n",
        "The function starts by creating a Sequential model object, then it adds an input layer to the model, specifying the shape of the inputs expected input. Next, it stacks on depth number of consecutive dense layers, applying the activation function specified in the \"activation\" parameter after each Dense block. Then, it adds an output layer to the model, specifying that it should predict 1 variable and using a 'linear' activation function so as not to constrain the output. It then specifies the optimizer to use (Adam optimizer) and the learning rate. Finally, it compiles the model by specifying the loss function to minimize (mean squared error). The function returns the model after displaying the summary of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7894d4d",
      "metadata": {
        "id": "f7894d4d"
      },
      "outputs": [],
      "source": [
        "def fullyconnected_sequential(\n",
        "    input_shape: int,  # How many predictors?\n",
        "    width: int,  # How wide should the layers be?\n",
        "    depth: int,  # How many layers?\n",
        "    activation: str,  # What nonlinearity to use?\n",
        "    learning_rate=10**(-3),  # What learning rate?\n",
        "    final_activation: str = \"linear\",  # Final activation\n",
        "):\n",
        "    # Create a model object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Then just stack layers on top of one another\n",
        "    # the first specifies the shape of the inputs expected input\n",
        "    model.add(Input(input_shape, name=\"Inputs\"))\n",
        "\n",
        "    # Then we stack on depth number of consectutive dense layers\n",
        "    # To write more compact code we can include the activation\n",
        "    # function we want to apply after each Dense block in the\n",
        "    # call itself.\n",
        "    for i in range(depth):\n",
        "        model.add(Dense(width, activation=activation))\n",
        "\n",
        "    # Finally we add an output layer, we want to predict\n",
        "    # 1 variable, and we will probably use a linear output\n",
        "    # layer, so we don't constrain the output\n",
        "    model.add(Dense(1, activation=final_activation))\n",
        "\n",
        "    # Next we need to specify the optimiser we want to use and what learning rate to use\n",
        "    opt = Adam(learning_rate)\n",
        "\n",
        "    # Finally we compile the model, specifying the loss we want to minimise\n",
        "    model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "    # Afterwards we can summarise the model to see the shapes\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b74335",
      "metadata": {
        "id": "a5b74335"
      },
      "source": [
        "### Functional Model\n",
        "\n",
        "For more advanced architectures, it's good to use the functional approach to writing networks. This is very similar to the syntax of Pytorch.\n",
        "\n",
        "Here we stitch together a model, by passing one layer into the next layer. \n",
        "\n",
        "This code defines a function `fullyconnected_functional`. The function takes several parameters:\n",
        "\n",
        "- `input_shape`: an integer representing the number of predictors.\n",
        "- `width`: an integer representing how wide the layers should be.\n",
        "- `depth`: an integer representing how many layers the network should have.\n",
        "- `activation`: a string representing the non-linear activation to use (e.g. 'relu', 'sigmoid', etc.).\n",
        "- `learning_rate`: a float representing the learning rate of the optimizer (default value is 10^-3).\n",
        "- `final_activation`: a string representing the activation function for the final layer(default value is 'linear').\n",
        "\n",
        "The function starts by creating an input layer, and then assigns it to a variable \"inputs\" and another variable \"hidden\". Then, we repeatedly stitch a new Dense layer to the object \"hidden\" for the number of times specified in the \"depth\" parameter. This adds another layer onto the stack each time. Next, we add the output layer to the model, specifying that it should predict 1 variable and using a 'linear' activation function so as not to constrain the output. It then creates the model by specifying the input layers and output layers, this approach allows to create a model with multiple inputs and outputs if appropriate for the problem. Finally, it specifies the optimizer to use (Adam optimizer) and the learning rate, compiles the model by specifying the loss function to minimize (mean squared error) and displays the summary of the model and returns the model.\n",
        "\n",
        "In this simple model, there are few benefits to this approach, however, on more intricate networks, the enables forking and merging of paths within the network and even using multiple inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848ff69b",
      "metadata": {
        "id": "848ff69b"
      },
      "outputs": [],
      "source": [
        "def fullyconnected_functional(\n",
        "    input_shape: int, width: int, depth: int, activation: str, learning_rate=10**(-3), final_activation: str = \"linear\"\n",
        "):\n",
        "    # First we create an input layer\n",
        "    inputs = Input(input_shape, name=\"Inputs\")\n",
        "\n",
        "    # Pass it to the hidden variable we will reuse\n",
        "    hidden = inputs\n",
        "\n",
        "    for i in range(depth):\n",
        "        # Now we repeatedly apply a Dense layer to the object each time this adds another layer onto the stack\n",
        "        hidden = Dense(width, activation=activation)(hidden)\n",
        "\n",
        "    # Finally stitch on the output layer\n",
        "    output = Dense(1, activation=\"linear\")(hidden)\n",
        "\n",
        "    # And the model itself is created by specifying the input layers and output layers.\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    # Next we need to specify the optimiser we want to use and what learning rate to use\n",
        "    opt = Adam(learning_rate)\n",
        "\n",
        "    # Finally we compile the model, specifying the loss we want to minimise\n",
        "    model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "    # Afterwards we can summarise the model to see the shapes\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f3d60b",
      "metadata": {
        "id": "14f3d60b"
      },
      "source": [
        "#### Adam Optimiser\n",
        "\n",
        "When training a neural network, we use an optimization algorithm to adjust the parameters of the model in order to minimize the loss function. Notice that the optimiser we use is called `Adam` instead of the classic gradient descent algorithm described during the lessons.\n",
        "\n",
        "Gradient descent is a simple optimization algorithm that updates the model's parameters by taking a step in the direction of the negative gradient of the loss function. The step size is determined by a learning rate parameter, which controls how large the step should be. Gradient descent can work well for simple models, but can be slow to converge for more complex models.\n",
        "\n",
        "Adam, on the other hand, is a more advanced optimization algorithm that is based on gradient descent. It uses an adaptive learning rate, which means that the step size is adjusted for each parameter based on the historical gradient information. This can help the optimization converge faster and more efficiently. Adam also includes additional features such as momentum and RMSprop, which can further improve the optimization process. This makes Adam more similar to the Conjuage Gradient method in classic numerical optimisation. Choosing Adam can improve the optimization process and make it converge faster and more efficiently.\n",
        "\n",
        "#### Model Compiler\n",
        "\n",
        "Also note that we have to compile these models. Something that is quite uncommon in Python. Compiling a model in TensorFlow is necessary to specify the loss function, optimizer and metrics that are used to train and evaluate the model that is defined on a computational graph. It also sets the model in a state ready to be used for training and inference and allows integration with other high-level libraries like Keras we use here.\n",
        "\n",
        "### Creating the Model\n",
        "Create neural network object you can use either of the functions we defined above\n",
        "\n",
        "\n",
        "Try changing the depth and see what the summary says:\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\"> \n",
        "<b>Alternative:</b><code>\n",
        "model = fullyconnected_sequential(\n",
        "    time_of_day_train_norm.shape[1], depth=3, width=32, activation=\"tanh\", learning_rate=10**(-3)\n",
        ")</code>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b717e3fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b717e3fd",
        "outputId": "ea82549e-8314-4a9d-d5ea-504d3907eebd"
      },
      "outputs": [],
      "source": [
        "model = fullyconnected_functional(\n",
        "    time_of_day_train_norm.shape[1], depth=3, width=32, activation=\"tanh\", learning_rate=10**(-3)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34989018",
      "metadata": {
        "id": "34989018"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b> We have 2000 parameters to learn. This is many fewer than the number of examples, so we should not be too worried about overfitting.</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d17e383",
      "metadata": {
        "id": "4d17e383"
      },
      "source": [
        "## Model training\n",
        "\n",
        "The `fit` function implements the training loop for a model in TensorFlow. \n",
        "\n",
        "The first two arguments passed to the `fit` function are the training data and labels. In this case, the training data is `time_of_day_train_norm` and the labels are `forecast_error_train`. These are the inputs and outputs that the model will use to learn during training.\n",
        "\n",
        "The `batch_size` argument specifies the number of samples per gradient update. The `epochs` argument is the number of times the model will cycle through the data.\n",
        "\n",
        "Once the training is done, the model will be optimized to make predictions on new data with the same features.\n",
        "\n",
        "### Validation Strategies\n",
        "\n",
        "We learned that we can only use the test data for a final evaluation of the model performance after we are done tweaking the model.\n",
        "\n",
        "However, we need data to evaluate the neural network after each epoch, to see how well the training is doing on unseen data. Keras has implemented the `validation_split`, which takes a percentage of the data automatically as a validation holdout.\n",
        "\n",
        "Alternatively, we can user the argument `validation_data` which provides explicit data to evaluate the performance of the model during training. It is used to test the model during the training process and make sure it's not overfitting. In this case, we split the training data again to get the validation data as `time_of_day_val_norm` and the validation labels are `forecast_error_val`. Note that this data will perform slightly better, since it's normalised with the original training data. Ideally, we would get a validation holdout before standardization, in this particular case, we can get away with it to compare the performance of the `validation_split` vs. the `validation_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b46cd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40b46cd2",
        "outputId": "a3b8d75a-5575-432a-8d9a-05e70e0b1c39"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    time_of_day_train_norm,\n",
        "    forecast_error_train,\n",
        "    validation_split=0.15,\n",
        "    batch_size=128,\n",
        "    epochs=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c5208ef",
      "metadata": {
        "id": "4c5208ef"
      },
      "source": [
        "In this problem we have a large amount of data and a relatively small number of parameters to train, we therefore see that the model converges very quickly, with the loss decreasing little after the first epoch.\n",
        "\n",
        "We'll use the `train_test_split`function from scikit-learn again to subdivide the training data into an extra validation holdout set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecad2d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecad2d6",
        "outputId": "0f8c6d6a-457a-4b0f-a2ee-05e0061004c5"
      },
      "outputs": [],
      "source": [
        "time_of_day_train_small_norm, time_of_day_val_norm, forecast_error_train_small, forecast_error_val = train_test_split(\n",
        "    time_of_day_train_norm, forecast_error_train, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    time_of_day_train_small_norm,\n",
        "    forecast_error_train_small,\n",
        "    validation_data=(time_of_day_val_norm, forecast_error_val),\n",
        "    batch_size=128,\n",
        "    epochs=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f06c96",
      "metadata": {
        "id": "a7f06c96"
      },
      "source": [
        "In other problems it may take far longer training to reach this point, or even be impossible if a network is not appropriate for the data provided.\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "Finally we can do a numerical evaluation how well the model performs on unseen data.\n",
        "\n",
        "Purely, as a teaching device, we'll also evaluate the model on training data. This number is relatively meaningless standing by itself, as the model will always perform on training data as long as the model converged. The validation data is unseen as training, but was involved in the optimization process, which can have indirect optimization consequences, by us adjusting the architecture manually and generally making design choices based on the validation results.\n",
        "\n",
        "But it's good to learn, why we test on actual unseen data and use the training value as the lower bound for our expectations of the final evaluation of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbbabb13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbbabb13",
        "outputId": "a21e66de-3014-4108-ad56-53dc2abfa60b"
      },
      "outputs": [],
      "source": [
        "train_loss = model.evaluate(time_of_day_train_norm, forecast_error_train)\n",
        "print(\"Training Mean Squared Error:\", train_loss)\n",
        "\n",
        "val_loss = model.evaluate(time_of_day_val_norm, forecast_error_val)\n",
        "print(\"Validation  Mean Squared Error:\", val_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "583c3d36",
      "metadata": {
        "id": "583c3d36"
      },
      "source": [
        "Here we see the actual performance of our model compared based on true unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b86546",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18b86546",
        "outputId": "be2b475f-0e11-4476-db73-eb2e923cf01a"
      },
      "outputs": [],
      "source": [
        "test_loss = model.evaluate(time_of_day_test_norm, forecast_error_test)\n",
        "print(\"Test  Mean Squared Error:\", test_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7091771c",
      "metadata": {
        "id": "7091771c"
      },
      "source": [
        "### Visualization for Evaluation\n",
        "\n",
        "We can create some fake data to cover the entire day and get predictions to visualize the entire space of the data. \n",
        "\n",
        "This is not always possible, but that's what we have this tutorial data for to gain an intuitive understanding of the methods we apply. This creates an array of time of day values spanning from 0 to 24, with a step of 0.001. This is a full range of time of day values that we want to make predictions on. The array is then reshaped to have a single axis, this is done with the `[..., np.newaxis]` slice.\n",
        "\n",
        "Then we apply the same standardization procedure (using the fitted `scaler` object) on the full range of time of day values as the one used on the training and test data, to ensure that the new data has the same scale as the data the model was trained on.\n",
        "\n",
        "Finally, the code uses the `predict()` function to make predictions on the normalized full range of time of day values. The predict function returns an array of predicted forecast errors, one for each input time of day value. The variable `forecast_error_full_range_predicted` stores these prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd3ae3bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd3ae3bf",
        "outputId": "56e0a375-6981-4881-8f01-295033be5a7f"
      },
      "outputs": [],
      "source": [
        "time_of_day_full_range = np.arange(0, 24, 0.001)[..., np.newaxis]\n",
        "time_of_day_full_range_norm = scaler.transform(time_of_day_full_range)\n",
        "forecast_error_full_range_predicted = model.predict(time_of_day_full_range_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddad7ab6",
      "metadata": {
        "id": "ddad7ab6"
      },
      "source": [
        "Then we create an image of time of day values against forecast error values. The image is created by using a function called `imgBufferFromVectors` which takes a set of `x` and `y` values and creates an image.\n",
        "\n",
        "The function takes these arguments:\n",
        "\n",
        "- `time_of_day_test`: the x values, representing the time of day\n",
        "- `forecast_error_test`: the y values, representing the forecast error\n",
        "- `nx`: the number of pixels in the x-axis of the image\n",
        "- `ny`: the number of pixels in the y-axis of the image\n",
        "- `extent`: the range of values to be plotted in the image, if empty it will use the min and max of the x and y values.\n",
        "- `calc_average`: a boolean flag indicating whether to calculate the average of the input values or not.\n",
        "\n",
        "The function then returns the image as a buffer, the extent of the axis and the count of values in the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7987db66",
      "metadata": {
        "id": "7987db66"
      },
      "outputs": [],
      "source": [
        "tod_buffer, ax_extent, count = imgBufferFromVectors(\n",
        "    time_of_day_test, forecast_error_test, nx=256, ny=256, extent=[], calc_average=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d657e2f7",
      "metadata": {
        "id": "d657e2f7"
      },
      "source": [
        "Let's plot the number of measurements at each time of day against the forecast error.\n",
        "\n",
        "The red line shows the best fit.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\"> <b>Note:</b> The model (red line) is better than nothing, but does not account for the variation in 2m temperature error at single time of day (eg. at 14:00). Another predictor is required. We try using the soil temperature. In comparison to the regression model, the result of the neural etwork is less smooth which can be a good OR a bad thing.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eade6b39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "eade6b39",
        "outputId": "37231c2c-80cf-4b87-c87b-1f23f2dc6126"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.log((count == 0.0) + count), cmap=\"Blues\", origin=\"lower\", extent=ax_extent, aspect=\"auto\")\n",
        "\n",
        "plt.xlim([0, 24])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Time of day\")\n",
        "plt.ylabel(\"2m temperature error ($^\\mathrm{o}$C)\")\n",
        "cb = plt.colorbar()\n",
        "cb.set_label(\"Log( number of measurements )\")\n",
        "\n",
        "# Line of best fit\n",
        "plt.plot(time_of_day_full_range, forecast_error_full_range_predicted, \"red\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2794b5",
      "metadata": {
        "id": "3d2794b5"
      },
      "source": [
        "## Improving the Model\n",
        "\n",
        "Now we can start to play around.\n",
        "\n",
        "Let's add more predictors. \n",
        "\n",
        "We will add a second predictor, the model soil temperature. As we will see below, there is a complex structure in the pattern of forecast error in the 2D space of time of day & soil temperature. \n",
        "\n",
        "How well can the model learn this?\n",
        "\n",
        "### Visualize the Soil Temperature Data\n",
        "\n",
        "This code is plotting a 2D histogram of the relationship between forecast error, soil temperature and time of day. \n",
        "\n",
        "Notice how blue shows that the observation is warmer than the forecast and red shows that forecast is warmer than the observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b379f24d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "b379f24d",
        "outputId": "9dba5a6e-546c-4afc-8116-a5ddd794cc0f"
      },
      "outputs": [],
      "source": [
        "# Make image of the error with the new predictor\n",
        "buffer, ax_extent, count = imgBufferFromVectors(\n",
        "    soil_temperature_test, time_of_day_test, forecast_error_test, 128, 256, extent=[], calc_average=True\n",
        ")\n",
        "\n",
        "# Plot the image of the error\n",
        "plt.imshow(buffer, vmin=-5, vmax=5, cmap=\"seismic\", origin=\"lower\", extent=ax_extent, aspect=\"auto\")\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel(\"Soil temperature ($^o$C)\")\n",
        "plt.ylabel(\"Local time of day (hours)\")\n",
        "cb = plt.colorbar()\n",
        "cb.set_label(\"Forecast - Observation ($^o$C)\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2055228",
      "metadata": {
        "id": "e2055228"
      },
      "source": [
        "In the image above we see clear structure, where the in evening the forecast is too warm if the soil is frozen and too cold if the soil is not.\n",
        "\n",
        "Can we learn a good representation of this error pattern?\n",
        "\n",
        "### Training a new model\n",
        "\n",
        "We'll train a neural network model using two predictors, time of day and soil temperature. \n",
        "\n",
        "The data for the two predictors is first concatenated and then standardized using `StandardScaler` again. Then we construct a functional model with depth and width of 3 and 32 respectively, using `tanh` activation function to mix things up and train.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">Again, this may take a couple of minutes</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "285729c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "285729c8",
        "outputId": "7618c058-62c1-4ba2-ba5c-c63086814540"
      },
      "outputs": [],
      "source": [
        "# Create the input features\n",
        "X_train = np.concatenate([time_of_day_train, soil_temperature_train], axis=-1)\n",
        "X_test = np.concatenate([time_of_day_test, soil_temperature_test], axis=-1)\n",
        "\n",
        "# Standardise the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Construct a model, this time with 2 predictors\n",
        "model_with_soil = fullyconnected_functional(\n",
        "    X_train.shape[-1], depth=3, width=32, activation=\"tanh\", learning_rate=10**(-3)\n",
        ")\n",
        "\n",
        "# Alternative activation functions are tanh, sigmoid, softmax, relu, softplus...\n",
        "\n",
        "# Train the model using the data\n",
        "model_with_soil.fit(X_train, forecast_error_train, validation_split=0.15, batch_size=128, epochs=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa19cd5f",
      "metadata": {
        "id": "aa19cd5f"
      },
      "source": [
        "### Evaluating the New Model\n",
        "\n",
        "Let's do some evaluation on the unseen test data!\n",
        "\n",
        "We'll calculate the mean absolute error and the RMSE of the uncorrected forecast and the corrected forecast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0baf12e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0baf12e",
        "outputId": "3d52675a-2644-4c3e-e25e-2da58162ccb7"
      },
      "outputs": [],
      "source": [
        "# Calculate Root Mean Square error of predictions:\n",
        "\n",
        "zero_test = 0.0 * forecast_error_test\n",
        "print(\"Mean Absolute Error Uncorrected:\", metrics.mean_absolute_error(zero_test, forecast_error_test))\n",
        "print(\"Root Mean Squared Error Uncorrected:\", np.sqrt(metrics.mean_squared_error(zero_test, forecast_error_test)))\n",
        "\n",
        "forecast_corrected = forecast_error_test - model_with_soil.predict(X_test)\n",
        "\n",
        "print(\"Mean Absolute Error Corrected:\", metrics.mean_absolute_error(zero_test, forecast_corrected))\n",
        "print(\"Root Mean Squared Error Corrected:\", np.sqrt(metrics.mean_squared_error(zero_test, forecast_corrected)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4c9c2a",
      "metadata": {
        "id": "af4c9c2a"
      },
      "source": [
        "By using two predictors we can impove the forecast of 2m-temperature by ~0.1C.\n",
        "\n",
        "#### Visual Evaluation\n",
        "\n",
        "Let's see how the model corrects the forecast across the full 2D space.\n",
        "\n",
        "We'll run the trained model over a range of values for the input variables `soil_temperature` and `time_of_day`. \n",
        "\n",
        "It first defines the range of values for these variables using `nx` and `ny`, which are the dimensions of the input buffer, and the `ax_extent` which is the range of values observed in the data. Then it creates the input data by stacking the meshgrid of these variable ranges using `np.meshgrid`, and transforms this input data using the `scaler` that was fit earlier on the training data. Then we predict the output using this input data and reshapes this output back to 2D plot using `raw_pred.reshape(input_buffer.shape[:-1])` for us to plot!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ffa23d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68ffa23d",
        "outputId": "55a3bcf6-b44e-429b-a792-b72fc8491c2f"
      },
      "outputs": [],
      "source": [
        "# Run the fit model over the plot domain\n",
        "\n",
        "# The x and y values of each point in the plot image, this covers\n",
        "# the range of data observed in the data\n",
        "nx = buffer.shape[0]\n",
        "ny = buffer.shape[1]\n",
        "x_st = np.linspace(ax_extent[0], ax_extent[1], nx)  # Represents soil_temperature\n",
        "y_tod = np.linspace(ax_extent[2], ax_extent[3], ny)  # Represents time_of_day\n",
        "\n",
        "# Create the input data\n",
        "input_buffer = np.stack(np.meshgrid(y_tod, x_st), axis=-1)\n",
        "X_plot = scaler.transform(input_buffer.reshape(-1, X_train.shape[-1]))\n",
        "\n",
        "# Predict and reshape prediction back to 2D plot\n",
        "raw_pred = model_with_soil.predict(X_plot)\n",
        "model_buffer = raw_pred.reshape(input_buffer.shape[:-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953545c5",
      "metadata": {
        "id": "953545c5"
      },
      "source": [
        "Let's compare the images!\n",
        "\n",
        "Notice that we're fixing the range of the plot between -5 and 5 to make these plots intuitively comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f0ab18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "13f0ab18",
        "outputId": "c5e93d18-14f4-4412-cf0a-97b390d07411"
      },
      "outputs": [],
      "source": [
        "# Plot the image of the error\n",
        "plt.imshow(buffer, vmin=-5, vmax=5, cmap=\"seismic\", origin=\"lower\", extent=ax_extent, aspect=\"auto\")\n",
        "\n",
        "plt.grid()\n",
        "plt.title(\"Forecast Error or Raw Data\")\n",
        "plt.xlabel(\"Soil temperature ($^o$C)\")\n",
        "plt.ylabel(\"Local time of day (hours)\")\n",
        "cb = plt.colorbar()\n",
        "cb.set_label(\"Forecast - Observation ($^o$C)\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot the model output where we have data\n",
        "plt.imshow(\n",
        "    (model_buffer) * (count > 0), vmin=-5, vmax=5, cmap=\"seismic\", origin=\"lower\", extent=ax_extent, aspect=\"auto\"\n",
        ")\n",
        "\n",
        "plt.grid()\n",
        "plt.title(\"Model Output of Predicted Forecast Error\")\n",
        "plt.xlabel(\"Soil temperature ($^o$C)\")\n",
        "plt.ylabel(\"Local time of day (hours)\")\n",
        "cb = plt.colorbar()\n",
        "cb.set_label(\"Neural Network model ($^o$C)\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot the model over the whole domain\n",
        "plt.imshow(model_buffer, vmin=-5, vmax=5, cmap=\"seismic\", origin=\"lower\", extent=ax_extent, aspect=\"auto\")\n",
        "\n",
        "plt.grid()\n",
        "plt.title(\"Model Output of Extrapolating to the Full Domain\")\n",
        "plt.xlabel(\"Soil temperature ($^o$C)\")\n",
        "plt.ylabel(\"Local time of day (hours)\")\n",
        "cb = plt.colorbar()\n",
        "cb.set_label(\"Neural Network model ($^o$C)\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782f5fc6",
      "metadata": {
        "id": "782f5fc6"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "As we add more predictors and complexity to our model, it becomes better and better. But, our measurements of the forecast error are not perfect. There is some noise. We don't want our model to capture this. But an overly complex model will. We need a simpler model, or more data. Fitting a model that is too complex for the data is causes overfitting. \n",
        "\n",
        "Here we have a large number of observations and still relatively small number of free parameters, so overfitting is unlikely. We see that during training our errors on the training & testing dataset are comparable.\n",
        "\n",
        "Away from where data has been provided the model does not have constraints. We should not trust this part of the space without additional validation.\n",
        "\n",
        "We also see different model corrections for hour 23 and hour 0, when these should be closely correlated, as they're mere seconds away from each other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e7c3e0",
      "metadata": {
        "id": "f4e7c3e0"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1. Can you beat these predictions by changing the model architecture?\n",
        "\n",
        "Play around with activations, depth, width, learning rate of the neural network.\n",
        "\n",
        "2. Is there a way of building in any prior knowledge to even this simple setup?\n",
        "\n",
        "Perhaps you can encode the fact that 0 hour follows 24? Does this help the prediction?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d833525e",
      "metadata": {
        "id": "d833525e"
      },
      "source": [
        "Now that you've had a proper introduction to deep learning, you may quench your curiosity and go back to the Weatherbench notebook from tier 1 to inspect a convolutional neural network.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f4133980c8e4ffdbca2a5f6a64fd93a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f899f69e52f40039d893cbb47938d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc45aea02224494e9758bbfa4790fbaa",
            "placeholder": "​",
            "style": "IPY_MODEL_b26b31016f7e4f49acdc0714e49135d8",
            "value": " 87.8M/87.8M [01:30&lt;00:00, 1.06MB/s]"
          }
        },
        "1b04146f6af542a28bcb833e8789f131": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb0061217dc4d28ac9841706edc93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c8d2d0cea59400f8c8235430f801ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21dd2a43253842018dd587b905e21ee2",
            "max": 92621248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d0287a5ef9b44d8ac7ca90ef7080cb4",
            "value": 92621248
          }
        },
        "1d924eea57bf4996a8daa5f5c3116ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7420e55e139241bab475af2c1e3a0db4",
            "placeholder": "​",
            "style": "IPY_MODEL_64882a140c39440e82ab736416ab248e",
            "value": "time_of_day.csv: 100%"
          }
        },
        "2159bfe5874b4988a12a86a51276f091": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "21dd2a43253842018dd587b905e21ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436463275b9d41de94b5537597e3f6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a22dc23cee943e68fead37f9088dcaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e359bb2323148688f83cef9531778fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d634ff4adca4ac79034ee976fd71d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b04146f6af542a28bcb833e8789f131",
            "max": 92096414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef4cf06d35c34b96935c44f6d4cbbe0b",
            "value": 92096414
          }
        },
        "5f4309b054b548819d520242304213d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64882a140c39440e82ab736416ab248e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b1cb3e8476434b906e317c9328bd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d7eb99a75c46c3a83f820f2d37a20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d924eea57bf4996a8daa5f5c3116ffe",
              "IPY_MODEL_d2d85c288705419a94e8f3590951982c",
              "IPY_MODEL_e00c7590687844a6ba18d8be5a79e657"
            ],
            "layout": "IPY_MODEL_cd6b4f403db84f9db6c913a879a85f31"
          }
        },
        "7420e55e139241bab475af2c1e3a0db4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752b9d94e5384d3cb757d45da2b4033d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4d084e1fcc4144a1cd651f23c53ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8d0287a5ef9b44d8ac7ca90ef7080cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92a9cc49337c403fb405d8c2e134c3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752b9d94e5384d3cb757d45da2b4033d",
            "placeholder": "​",
            "style": "IPY_MODEL_64b1cb3e8476434b906e317c9328bd2a",
            "value": " 88.3M/88.3M [01:41&lt;00:00, 1.11MB/s]"
          }
        },
        "938dbdbbb5414086a17a4e28b61c9c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4309b054b548819d520242304213d4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2dd4a70b77f493fa8091c60bfebc0c0",
            "value": "soil_temperature.csv: 100%"
          }
        },
        "99698e34064f41cfa0bc73c46ba3663b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec578e613734c778d40ccacbfa46287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99698e34064f41cfa0bc73c46ba3663b",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb0061217dc4d28ac9841706edc93a7",
            "value": "forecast_error.csv: 100%"
          }
        },
        "b26b31016f7e4f49acdc0714e49135d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc45aea02224494e9758bbfa4790fbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6b4f403db84f9db6c913a879a85f31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d2d85c288705419a94e8f3590951982c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e359bb2323148688f83cef9531778fc",
            "max": 97404738,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a22dc23cee943e68fead37f9088dcaf",
            "value": 97404738
          }
        },
        "dbd0dc09e89e42df8948ee0d3d830dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aec578e613734c778d40ccacbfa46287",
              "IPY_MODEL_1c8d2d0cea59400f8c8235430f801ef3",
              "IPY_MODEL_92a9cc49337c403fb405d8c2e134c3d5"
            ],
            "layout": "IPY_MODEL_2159bfe5874b4988a12a86a51276f091"
          }
        },
        "e00c7590687844a6ba18d8be5a79e657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4133980c8e4ffdbca2a5f6a64fd93a",
            "placeholder": "​",
            "style": "IPY_MODEL_436463275b9d41de94b5537597e3f6ea",
            "value": " 92.9M/92.9M [01:31&lt;00:00, 1.25MB/s]"
          }
        },
        "e1437f990544457687ab3749da91fa4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_938dbdbbb5414086a17a4e28b61c9c5b",
              "IPY_MODEL_5d634ff4adca4ac79034ee976fd71d89",
              "IPY_MODEL_0f899f69e52f40039d893cbb47938d37"
            ],
            "layout": "IPY_MODEL_7b4d084e1fcc4144a1cd651f23c53ee8"
          }
        },
        "e2dd4a70b77f493fa8091c60bfebc0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef4cf06d35c34b96935c44f6d4cbbe0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
